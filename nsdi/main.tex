\documentclass[letterpaper,twocolumn,10pt]{article}
\usepackage{usenix2019_v3}
\usepackage{local}

\begin{document}
\date{}
% <<<<<<< Updated upstream
% \title{\Large \bf \ulang: Towards Portable, Modular and Composable Dataplane Programs}
% =======
\title{\Large \bf Reusing Dataplane Programs Using \ulang}
% >>>>>>> Stashed changes
\author{{\rm Paper \#XXX}\\ Anonymous author(s)}
\maketitle

\begin{abstract}
Domain-specific languages such as P4 enable flexible and efficient
packet-processing using primitives such as programmable parsers and
re-configurable match-action tables. However, the P4 ecosystem exposes
details of the underlying architecture, which ties programs to
specific architectures and makes it difficult to write composeable
libraries of code that can be reused across many different programs.

To address this challenge, we present the design and implementation of
a logical target, MicroP4 (\uswitch), that decouples P4 programs from
lower-leverl, architecture-specific constructs and naturally supports composition.
We present the design of the higher-level architecture (\uarch),
which models \uswitch and abstracts away from hardware-level details without sacrificing
expressiveness. Using realistic examples, we show how \uswitch enables
modular programming and composition, and we present an implementation
of the \ucomp compiler that generates code for lower-level
architectures which are implemented by real target devices.
\end{abstract}



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%% INTRODUCTION %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Introduction}
\label{sec:intro}
Over the last decade, the synergistic development of packet-processing
hardware and software has fundamentally changed how networks are built
and operated. Hardware platforms such as
RMT~\cite{bosshart2013forwarding} provide tremendous flexibility for
customizing the forwarding plane without having to fabricate new
chips, while languages such as P4~\cite{bosshart2014p4, p4lang} enable
programmers to describe rich packet-processing functions in terms of
high-level abstractions such as parsers and match-action tables.

In order to support different kinds of targets (e.g., software
switches, ASICs, FPGAs, etc.), P4 allows programmable and
fixed-function blocks to be arranged into different layouts as
specified by an architecture declaration. For example, the Portable
Switch Architecture (PSA)~\cite{psa} models a switch with a
programmable parser, programmable ingress pipeline, fixed-function
scheduler and queues, programmable egress pipeline, and programmable
deparser (Figure \ref{subfig:psa-model}).  PSA programs supply P4 code
for each programmable block.  P4 also allows to specify
target-specific features and data as a part of the target's
architecture declaration.  PSA programs can use features and data
specific to the architecture in the code for programmable block.
While this design allows the language to flexibly accommodate a wide
range of targets, it also creates a tight coupling between programs
and architectures, which makes it difficult to write programs in a
compositional manner or reuse common code fragments in different
programs.

For example, \texttt{switch.p4}~\cite{switch.p4} handles several dozen
different protocols and functions (e.g., L2 switching, L3 routing,
tunneling, etc.,). But the code is written against a global collection
of metadata and parsed headers. To use the code in \texttt{switch.p4}
to implement an Ethernet switch, it would be necessary to detangle the
L2-specific functionality from the extraneous code in the rest of the
program. Without a detailed understanding of the overall structure of
the top-level program, it is difficult or impossible to reuse code
fragments at finer granularity.

Consider a simple scenario with two code fragments, as shown in
\cref{fig:l2.p4,fig:ipv4.p4}. The first code fragment, \texttt{l2},
parses the ethernet header, and modifies the ethernet addresses using
the next hop (\texttt{nh\_id}), which is supplied as an argument, and
finally deparses the packet. The second code fragment, \texttt{ipv4},
parses the IPv4 header, uses longest-prefix matching to determine the
next hop, decrements the \texttt{ttl} field and, finally, deparses the
packet.  Note that neither \texttt{ipv4} nor \texttt{l2} is a complete
packet-processing program: the former does not generate a functionally
correct packets, while the latter is parameterized on the next hop and
so does not specify forwarding behavior. However, we could use
\texttt{l2} with any other routing scheme (e.g., IPv6, MPLS, etc.) to
obtain a valid program.

\begin{figure}[ht]
\begin{lstlisting}[frame=none, escapechar=!]
// l2.p4: parse and process only L2 header
parser P(packet_in pin, out hdr_t ph) {
  state start { pin.extract(ph.eth); }
}
control Pipe(inout hdr_t ph, inout sm_t sm,
             in bit<16> !\colorbox{mygray}{nh\_id}!) {
  action drop () {}
  action forward(bit<48> dest_mac, bit<48> src_mac, bit<8> port) {
    ph.eth.dstMac = dest_mac;
    ph.eth.srcMac = src_mac;
    sm.out_port = port;
  }
  table forward_tbl {
    key = { nh_id : exact; }
    actions = { forward; drop; }
  }
  apply { forward_tbl.apply(); }
}
control D(packet_out po, in hdr_t ph) {
  apply { po.emit(ph.eth); }
}
\end{lstlisting}
\caption{Ethernet Processing}
\label{fig:l2.p4}
\end{figure}

\begin{figure}[ht]
\begin{lstlisting}[frame=none, escapechar=!]
// ipv4.p4: parse and process only IPv4 header
struct meta_t { bit<16> type; }
parser P(packet_in pin, out hdr_t ph) {
  state start {
    pin.extract(ph.ipv4);
    transition accept;
  }
}
control Pipe(inout hdr_t ph, out bit<16> !\colorbox{mygray}{nh\_id}!, inout sm_t sm) {
  action process(bit<16> nh) {
    ph.ipv4.ttl = ph.ipv4.ttl - 1;
    nh_id = nh; // setting out param
  }
  table ipv4_lpm_tbl {
    key = { ph.ipv4.dstAddr : lpm; }
    actions = { process; }
  }
  apply { ipv4_lpm_tbl.apply(); }
}
control D(packet_out po, in hdr_t ph) {
  apply { po.emit(ph.ipv4); }
}
\end{lstlisting}
\caption{IPv4 processing}
\label{fig:ipv4.p4}
\end{figure}

%% The current ecosystem of programmable data plane enforces programmers
%% to write code amenable to the target device's data plane architecture
%% and pipeline. Programmers write code for programmable blocks taking
%% into account their location in pipeline rather than compilers
%% automatically allocating code to the appropriate blocks. We believe
%% that devices should only expose abstraction for processing blocks and
%% the onus of code allocation to the blocks in pipeline should be on
%% compilers for the devices.

There is some prior work on modular composition of P4 programs.
Systems such as HyPer4 \cite{Hancock:2016:HUP:2999572.2999607},
HyperV~\cite{8038396}, and
P4Visor~\cite{Zheng:2018:PLV:3281411.3281436} provide constructs for
merging independent programs onto a single device. However, these
systems only handle programs that describe end-to-end
packet-processing functions. Hence, they lack mechanisms for enabling
selective reuse of library code, specifying interfaces between
modules, and facilitating inter-module communication. To write truly
modular P4 programs, a fundamentally different approach is needed.

To this end, this paper presents the design and implementation of
\ulang, a new architecture that provides fine-grained abstractions for
constructing dataplane programs. \ulang consists of two components: i)
Micro Switch Architecture (\uarch), which distills packet processing
to its essence, and abstracts away from device-specific structure, and
ii) a compiler, \ucomp, that maps one or more \uarch programs to a
standard PISA pipeline.
\todo{Describe the impact, i.e what \ulang enables, further to
appreciate why this is a good idea.}\\
\todo{Fair to say the \ulang enables us to write portable, modular, and composable programs?}

This paper makes the following contributions.\\
\todo{rethink contributions}\\
\begin{itemize}
\item We motivate the need for modular data plane programming using a
  series of realistic examples.
\item We introduce \uarch, a new P4 architecture designed to enable
  fine-grained composition of program snippets.
\item We develop techniques for compiling \uarch programs to the
  standard PISA model, including merging programs composed together 
  \hse{and scheduling them onto a single PISA pipeline}.
%   including merging programs composed together in
%   parallel or in sequence onto a single PISA pipeline.
\end{itemize}

% Although much work remains, we believe that \uarch represents a
% promising first step toward enabling modular data plane programs.




%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%% DATAPLANE PROGRAMMING %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Dataplane Programming}
\label{sec:background}
% Goals:
% i) implicit background on dataplane programming and highlight the
% key challenges, and
% ii) present the key insights of our approach

We briefly describe the current state of data plane programming using
P4 to understand challenges that hinder writing dataplane programs in
a portable, modular and composable manner (\cref{sec:challenges}).
Then, we derive insights to achieve our goals for dataplane
programming (\cref{sec:insights}) and give an overview of our approach
(\cref{sec:overview}).



\subsection{Challenges with current approach}
\label{sec:challenges}

% Brief background on P4 programming model and architecture
% TODO: shorten and put programmable-parser  and primitives words 
% here.
\refine{P4~\cite{bosshart2014p4} has emerged as a popular language for
specifying the packet-processing behaviour of re-configurable
switching chips, such as Barefoot Tofino~\cite{tofino} and Cavium
Xpliant~\cite{xpliant}, which are based on a pipeline of match-action
tables~\cite{bosshart2013forwarding}.} To support a variety of
\emph{target} devices, manufacturers provide target-specific
frameworks to program the devices. Such a framework also provides the
programming model, often called the \emph{architecture}, that provides
an abstract view of the target's processing pipeline. Specifically, an
architecture, such as \texttt{v1model}~\cite{v1model.p4}, for a
target, such as \texttt{simple\_switch} software
switch~\cite{simple_switch.md}, specifies the dataplane pipeline model
comprising a set of programmable and fixed-function blocks, flow of
packet, user-defined and target-specific (called \emph{intrinsic})
metadata in the pipeline, and semantics of target-specific constructs
such as actions and externs. For example, \cref{fig:arch-example}
shows dataplane pipelines and their processing blocks for
\texttt{v1model}~\cite{v1model.p4} and Portable Switch
Architecture (PSA)~\cite{psa}.
\begin{figure}[tb]
  \centering
  \includegraphics[width=\linewidth]{example-arch.pdf}
  \caption{Dataplane pipelines for example architectures}
  \label{fig:arch-example}
\end{figure}

To program a target, one can use P4 to specify the behavior of the
programmable blocks exposed in the architecture of the target. While
this approach allows supporting multiple targets which share the same
architecture, it also makes the P4 program dependent on
\begin{enumerate*}[label=(\roman*)]
  \item the target's dataplane pipeline,
  \item flow of packet and metadata in the pipeline, and
  \item target-specific constructs.
\end{enumerate*}
These dependencies pose multiple challenges for target-agnostic reuse
of independently developed P4 programs to build new ones:


% NOTE: Two main points:
% 1) across architectures: because pipeline model is different, it
% hinders portability and code reuse
% 2) even on the same architecture, a P4 program consists of
% sub-languages with different abstract machines. So, modular
% composition of programs is not possible.
% NOTE: introduce terms such as "abstract machine" with definition or
% examples

% First explain the problem with reuse across architectures
% (Portability)
\tightparbf{Challenge 1. P4 programs are specific to an architecture.}%
The structure of a P4 program is often dependent on the dataplane
pipeline model of the architecture for which it was written.
Architectures differ in the set of programmable-blocks and their
arrangement in the pipeline. So, when trying to reuse a program for
another target, if the architecture changes, it is often impossible to
reuse the same program with the new architecture without a complete
rewrite. For example, in \cref{fig:arch-example}, mapping the
functionality implemented for PSA's ingress deparser block to any
programmable block in \texttt{v1model}'s pipeline requires semantic
understanding of the blocks. Therefore, other than a manual rewrite,
there is no obvious automatic way to reuse the implementation of
programmable blocks across architectures.

Moreover, P4 programs often rely heavily on architecture-specific
metadata and constructs, such as resubmit, recirculate, clone,
etc.~\cite{simple_switch.md,psa}.  While this enables enable special
processing, such as replication, of packets, such dependency makes a
program tied to a specific architecture and undermines the program's
portability.

% (... and modularity)
\tightparbf{Challenge 2. P4 programs are monolithic.}
% TODO:
% Add some at least one direct reference to point 2 ``flow of packet 
% and metadata``. pieces of programs can be thought of many  ways.
% we have already mentioned about 'specifying behavior of 
% programmable blocks'. Another word pieces is confusing.
\refine{P4's programming model introduces unnecessary tight coupling 
among
pieces of the program which could be kept independent.} For example, 
in
\cref{fig:arch-example}, PSA's ingress parser initializes headers and
metadata which are processed by ingress control. To reuse the code for
ingress control block in another PSA-specific program, the new parser
must adhere to the headers and metadata generated by the previous
parser. Such coupling also manifests when trying to write modules for
otherwise independent packet-processing functions. This occurs because
P4 programs, often, use intrinsic and other metadata across a program
in an unrestricted manner~\cite{switch.p4}; it is difficult to split
such a program into clean modules which can be developed independently
and reused. More fundamentally, it breaks the notion of abstraction
needed to write modular programs. In fact, P4 does not enforce
sufficient scoping of data needed to develop independent modules. As a
result, even to update a small piece of functionality, developers need
to be aware of how each variable is used throughout the entire
program. Thus, tight coupling across program blocks and a lack of
proper scoping of data leads to monolithic programs, which makes it
extremely difficult to develop independent modules, thereby inhibiting
modularity.



% Then problem with writing modular code even on a single architecture
% (Composition)
\tightparbf{Challenge 3: Programmable blocks have heterogeneous
abstract machines.}%
The current approach also makes it hard to write composable dataplane
modules. To understand why, note that even for a fixed target, the
architecture usually contains packet-processing blocks with
heterogeneous execution models, also called \emph{abstract
machines}~\cite{p4lang,van1991machine}. For example in
\cref{fig:arch-example}, the parser blocks are described using a
sub-language of P4 which uses Finite State Machines (FSM) as its
abstract machine, while the control blocks are expressed in another
sub-language whose abstract machine models imperative control
flow~\cite{p4lang}. As the behavior of programmable blocks are
expressed in different sub-languages and abstract machines, a P4
program lacks a uniform or compatible interface between
packet-processing modules. This prevents modules to be composed
together to build larger programs. Going back to the earlier example,
in \cref{fig:l2.p4,fig:ipv4.p4}, ideally we would like to execute the
\texttt{ipv4} module (parser and control blocks) right before applying
\texttt{forward\_tbl} in \texttt{l2}'s \texttt{Pipe} control block so
that \texttt{nh\_id} is available in \texttt{forward\_tbl}. But the
existing P4 model does not support such composition.

% \hs{May be we can get away with summary and put shorter summary}
\deleted{
To summarize, there are three main challenges with current dataplane
programming model that hinders code portability, modularity and
composition:
\begin{enumerate}
  \item \hse{P4 programs are architecture-specific.}
    Different architectures vary in their dataplane pipeline model
    which have incompatible structure and semantics.  This renders P4
    programs written for one architecture not amenable to be ported to
    others.
  \item Architectures do not provide a clean abstraction that can
    decouple dataplane programs from targets and also do not enforce
    sufficient encapsulation and scoping of information. This makes it
    difficult to develop clean and independent modules.
  \item Programmable blocks within an architecture use heterogeneous
    abstract machines without a common interface. The lack of a
    compatible interface restricts composition of dataplane modules.
\end{enumerate}
}

To summarize, dataplane programs currently written in P4 are
\begin{enumerate*}[label=(\roman*)]
  \item not portable because of their affinity to architectures,
  \item monolithic because of huge data-sharing across
    processing-blocks within the pipeline and lack of scoping, and
  \item not composable because of heterogeneous abstract machines
    in processing-blocks and the lack of a uniform interface.
\end{enumerate*}




\subsection{Design goals and key insights}
\label{sec:goals}
\label{sec:insights}

Our main goal is to enable dataplane programming in a portable,
modular, and composable manner.

\tightpar{Portable:} Dataplane programs written for one target device
and architecture should be easily reusable across other targets and
architectures. For example, one should be able to port a program
originally written with \texttt{v1model} in mind on to PSA without
significant rewrite.

\tightpar{Modular:} Individual dataplane functionality for processing
packets can be developed in an independent manner agnostic of the
target as well as other dataplane functions. For example, one should
be able to write modules for L2 and L3 processing in an independent
manner.

\tightpar{Composable:} Modules for individual dataplane functions can
be composed together in custom ways to express complex dataplane
processing. For example, in \cref{fig:l2.p4,fig:ipv4.p4}, one should
be able to compose \texttt{ipv4} with \texttt{l2}, or replace
\texttt{ipv4} with modules for IPv6, MPLS etc. as needed.





\paragraph{Insights.}
We find that the root cause that restricts dataplane programming from
achieving our goals is the abstraction offered by current
architectures as discussed in~\cref{sec:challenges}.  Consequently,
our key insight is that in order to achieve the above goals, we need
% TODO:
% the generl term is misleading and confusing. We want to say in 
% clear words that out insigt is packet-processing abstractions based 
% on parser + MAT primitives are not enough, and we need abstraction 
% for entire dataplane 
\refine{\emph{to raise the level of abstraction that is general 
enough to
  express a wide range of functionality while also being realistic so
  that programs can be mapped to real architectures in an automatic
manner}}. Of course, introducing yet another architecture to unify
existing architectures would add significant complexity to the
ecosystem; instead, what we need is a \emph{logical} architecture that
acts as high-level description against which programs are written, and
this logical architecture maps to real architectures. This
architecture is logical in the sense that devices do not explicitly
implement it; rather, it captures the bare essence of packet
processing and exposes that to programs.

Based on our analysis in \cref{sec:challenges}, we found that the
challenges stem from inconsistent pipelines across architectures,
exposing target-specific externs, and a lack of uniform abstract
machine and interfaces with any existing architecture. Accordingly, we
believe that the logical architecture should have three main
components:
\begin{enumerate*}[label=(\roman*)]
  \item a logical pipeline that is expressive enough to encode a
    wide range of packet-processing functions while being general,
  \item a generic way to use target-specific features such as externs
    without introducing tight coupling, and
  \item a common interface so that packet-processing modules can be
    composed.
\end{enumerate*}



\subsection{Overview of our approach}
\label{sec:overview}
%% Give an overview of our approach, tying to the above discussion
%% Do not go into specific details yet.

To achieve our goals, portable, modular and composable dataplane
programming, without disrupting the existing workflow for P4, we
introduce the \ulang framework. \ulang implements the above insights
using three main components:
\begin{enumerate*}[label=(\roman*)]
  \item \uswitch: an intermediate logical device
  \item \uarch: an architecture for the logical device, and
  \item \ucomp: a compiler that translates \ulang programs into real
    target code.
\end{enumerate*}

Users write dataplane programs using an extended P4 language which
supports modularity and composition. These programs are written with
the \uarch architecture. While compiling, users specify the real
target architecture for which the \ulang programs should be
translated. This decouples programs from target architectures while
keeping the workflow very simple and intuitive.


% \hs{TODO: start with: \uarch raises the level of abstraction for 
% packet-processing from mere RMT based primitives to dataplane 
% pipeline model of target architectures. Therefor handling portability 
% problem. shorten to 3-4 sentence para}
\hs{TODO:shorten it}
\uarch provides a set of constructs to write modular code having a
common interface that hides the implementation of packet-processing
within each module. A module can be thought of receiving a complete or
partial packet along with certain metadata, process it as needed, and
send out one or more packets along with some metadata. Thus, each
module can be developed independently. Modules can pass information or
call each other through a well-defined compatible interface---caller
write packets and metadata to a logical input buffer for the callee.
By introducing these logical buffers, \uswitch abstracts away the
details of dataplane pipelines of real targets. \uarch also provides a
way to express special processing (e.g., packet replication) by
introducing logical externs that each module may use.

\ucomp compiles \ulang code for a specified target architecture
while conforming to the constraints of the target device in two main steps.
First, \ucomp compiles the program to a \uarch-specific Intermediate
Representation (IR). It transforms all programmable blocks into
match-action control blocks, thus homogenizing abstract machine for
each block. This allows for a natural transfer of execution-control
across modules, enabling composition and facilitating code reuse.
In the second step, it translates all control blocks and
\uarch-specific constructs into the control blocks and constructs
exposed by the target architecture.

\deleted{The logical pipeline models defined in \uarch do not completely
eliminate heterogeneity in packet-processing blocks (parser,
control) of the pipelines.
% However, constructs and pipeline models declared in \uarch allows to
% write programs by reusing the code developed in conformance of
% \uarch.
The design choices for \uarch are intentional to avoid disruptive
innovations in P4 language.  It partially address the above mentioned
challenges and leaves following two aspects for unaddressed.  $1$
creating P4 programs specific to \uarch and the logical device \ucomp.
$2$ heterogeneity in packet-processing blocks of P4 programs.  We
complement design choices of \uarch by designing and developing a
compiler, \ucomp, to address these aspects.
}



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%% MICRO-P4 %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{The \ulang framework}
\label{sec:microp4}
%% Describe each component of microP4
Now, we describe each component of \ulang which enable our goals for
dataplane programming.

\paragraph{\uswitch.}
\uswitch is an intermediate logical target with an abstract
programming model. It is designed to provide a high-level abstraction
that enables modular programming for dataplane without compromising on
the expressiveness.  It does so by allowing to write modules that
implement fine-grained packet processing and defining interfaces to
compose these modules.
\begin{figure}[htb]
    \centering
    \includegraphics[width=\linewidth]{uswitch-model}
    \caption{Abstract programming model for \uswitch}
    \label{fig:uswitch}
\end{figure}

\uswitch models each packet-processing module as a self-contained
\hse{black-box} execution unit, called a \emph{\uprogram}, and
executes it using the model shown in \cref{fig:uswitch}. A \uprogram
takes as input: a packet byte-stream, intrinsic metadata and arguments
for user-defined parameters. As output, it generates byte-streams,
metadata, and return values corresponding to one or more packets. Such
a model hides implementation details, such as headers types,
user-defined metadata and programmable blocks, of a \uprogram from
other \uprograms.  \uswitch fetches an element from a logical input
buffer for each \uprogram, executes the \uprogram and writes one or
more elements to the logical output buffer, which acts as input for
another. Note that these buffers only exist in the abstraction and do
not represent buffers in real target devices.

\paragraph{\uswitch Architecture (\uarch).}
To write portable \uprograms, we define \uswitch Architecture
(\uarch)---it specifies the dataplane as composition of logical
pipelines, called \emph{\upipeline}, where each \upipeline implements
a part of the complete packet processing on the device. A \upipeline
may map to one or more \uprograms. Each \upipeline is associated with
a \uarch interface, which specifies run-time parameters in a generic
way and declares programmable blocks required to be implemented for
the pipeline. In order 
% TODO: essence is not accurate here. In 3rd section, we would like 
% to have formal words
\refine{to capture the essence of packet-processing} and
expose a minimal interface, \upipelines comprise of only programmable
packet-processing blocks such as parser, match-action control blocks
and deparser. In addition, to abstract away from target-specific
constructs, \uarch defines \emph{logical} externs and metadata to
facilitate use of packet-processing features such as multicast,
cloning, etc. that are not part of P4 language but supported by
architectures of real-targets. Programmers can use the logical externs
to use such features.

\begin{figure}[tbh]
    \begin{subfigure}{\linewidth}
        \centering
        \includegraphics[width=\linewidth]{compilation-module.pdf}
         \caption{Module Compilation}
         \label{subfig:module-compilation}
    \end{subfigure}
    \begin{subfigure}{\linewidth}
        \centering
        \includegraphics[width=\linewidth]{compilation-main.pdf}
        \caption{Compilation to a Target Architecture}
        \label{subfig:compilation-to-target-architecture}
    \end{subfigure}
    \caption{Compiling \uprograms}
\end{figure}


\paragraph{\ulang and Compiler (\ucomp).}
To enable programmers to hide implementations and develop 
independent \uprograms, \ulang extends P4 with a construct 
that allows programmers to declare custom types, called \upackage, by 
implementing interfaces declared in \uarch. \upackages 
have in-built \texttt{apply} method that can be used to invoke their 
instance by supplying run-time parameters specified by their 
interfaces.
\hs{TODO: cont}

% \ucomp extends current P4 language and allows programmers to define 
% \texttt{package} types, declare their instances and invoke them using 
% the built-in \texttt{apply} method.
% This allows to hide implementation of package types and reuse them 
% using run-time parameters of their interfaces.
% Programmers can use sub-languages of P4 for parser and control blocks 
% to implement interfaces.
% \ucomp homogenizes abstract-machines of programmable blocks by 
% transforming parser and deparser blocks into match-action control 
% blocks. This transformation unifies the abstract-machines for 
% packet-processing allowing seamless transfer of execution control 
% across \uprograms.

\deleted{
Each \uprogram specializes a generic interface. The run-time 
interfaces enable easy reuse and hide implementation detail of the 
\uprograms, facilitating modular and incremental development. Using 
logical data plane model of \uarch, programmers can develop modular 
P4 code which is specific to \uarch. We design and develop MicroP4 
Compiler (\ucomp) to compile and transform \uprogram for 
architectures of real target devices, making \uprograms agnostic of 
architectures of real-targets. Programmer can use \ucomp to $(1)$ 
Create compiled libraries of \uprograms along with their control 
plane APIs, $(2)$ Link all the \uprograms used in the \uprogram of 
main instance and transform the program for a specified architecture 
of a real-target.
If the given source file does not contain an instance named, \ucomp 
generates a library by compiling it to an Intermediate Representation 
(IR) in json format (Figure \ref{subfig:module-compilation}). It also 
generates architecture-independent control-plane APIs, P4Runtime 
\cite{p4runtime} files. If the source file contains \emph{main} 
instance, it links all the supplied libraries and transforms the 
\uprogram of main instance for a given architecture (Figure 
\ref{subfig:compilation-to-target-architecture}). Programmers can 
include files containing definitions of data types (e.g., struct 
types 
of in and out parameters) used in run-time interfaces of \uprogram in 
libraries. \ucomp compiler generates either source P4 code for the 
specified architecture or an executable with architecture-specific CP 
APIs.
}

\sout{\ucomp perform static analysis to estimate possible packet 
sizes required to process all the transformed \uprograms in 
match-action control blocks of target architecture's pipeline.
\ucomp synthesizes P4 code for parser and deparer blocks of target architecture's pipeline to extract and emit required number of bytes from and to packet.
It allocates and schedules code of transformed \uprograms to control 
blocks of the target architecture's pipeline model while satisfying 
constraints posed by hardware details.}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%% MICRO Switch Architecture%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Micro Switch Architecture}
\label{sec:architecture}
In this section, we explain \uarch's logical constructs enabling
programming model (\cref{fig:uswitch}) of \uswitch. We designed 
the constructs that are amenable to \ucomp translations for 
portability without compromising on expressiveness of \uprograms. In 
\cref{sec:pipelines}, we explain interfaces and \upipelines
programmers require to implement in order to declare \upackages. 
\cref{sec:pipelines} explains a set of logical externs, which can be 
used to express packet-processing functionality in \upackages.


\subsection{Interfaces and \upipelines}
\label{sec:pipelines}
\deleted{
We explain composition requirements before introducing 
interfaces. To 
enable seamless composition, every \uprogram should be enable invoke 
another \uprogram with a uniform interface. A a caller halts its 
execution for the packet, puts the packet and the data related to it 
into the callee's input buffer, callee executes and puts all the 
resultant packets into its output buffer. The caller fetches 
proceesed packets from the callee's output buffer and continues 
execution.} 

\hs{
Micro-Pipe ---> one-to-many similar to orchestration-pipe-control\\
Micro-Pipe can be thought of as it allows replicate entire pipeline 
 (code replication). every instance of the pipeline has the same code.
 \\
orch-> allows to replicates packets only, and allows to execute 
different \upipelines on each copy.
}

\uarch provides three interface types, \texttt{Unicast}, 
\texttt{Multicast} and \texttt{Orchestration}.
Each type provides distinct run-time behavior and 
declarations of processing-blocks (\cref{fig:msa-interfaces}).
The processing-blocks in an interface type is modelled by a logical 
pipeline type, Micro or Orchestration, (\cref{fig:msa-pipelines}).
\begin{figure}[ht]
  \centering
  \includegraphics[width=\linewidth]{upipe-types}
  \caption{Types of \uarch pipelines}
  \label{fig:pipe-types}
\end{figure}

\begin{figure}[ht]
    \centering
    \begin{subfigure}{0.59\linewidth}
        \centering
        \includegraphics[trim=0 482 692 0, 
clip,scale=0.45]{msa-pipeline}
        \caption{Micro}
%         \label{subfig:micro}
    \end{subfigure}\vline
    \begin{subfigure}{0.41\linewidth}
        \centering
        \includegraphics[trim=0 480 805 
0,clip,scale=0.45]{micro-orchestration-pipeline}
        \caption{Orchestration}
%         \label{subfig:orchestration}
    \end{subfigure}
\caption{\uarch Pipelines}
\label{fig:msa-pipelines}
\begin{lstlisting}[frame=none]
Unicast<H,M,I,O,IO> (pkt p, inout sm_t sm, es_t es, in I i_param, out O o_param, inout IO io_param) {}
Multicast<H,M,I,O>(pkt p, in sm_t sm, es_t es, in I i_param, out_buf<O> ob)
Orchestration<I,O>(in_buf<I> ib, out_buf<O> ob) {}
\end{lstlisting}
\caption{\uarch Interfaces with run-time signatures}
\label{fig:msa-interfaces}
\end{figure}

\hse{ 
TODO: Why Orchestration and Micro.\\
Why 3 interfaces? \\
Their Apply calls \\
Micro pipeline models a sequence of processing blocks for 
a packet, where as Orchestration pipeline models only a control 
block. These distinctions are made to manage the complexity of 
\ucomp, but note that }

% \uarch allows programmers to write multiple implementations of 
% the same interface type to define multiple \upackages with 
% required run-time behaviors.
% Micro pipeline comprises of a parser, a control and a deparser 
% block.\uarch does not allow conditional statements in deparser 
% blocks of its % pipelines.
% For each pipeline type, it exposes one or more interface types.
% Each interface type comprises of a set of declarations for 
% programmable blocks and runtime signature.
% Programmers can provide implementations of the interface types 
% to create user-defined P4 package types.
% To implement an interface type, programmers need to implement 
% all the programmable blocks of the interface type.
% Programmers can instantiate variable of user-defined package 
% types and invoke the instances using built-in  \texttt{apply} 
% method similar to control blocks.
% The \texttt{apply} method of package instance can be called by 
% supplying arguments for run-time parameters of the interface 
% implemented by the package type.
% Every incoming packet is parsed and validated by the parser, if 
% parser terminates in \texttt{accept} state, then execution 
% control is transferred to micro control block.
% If the execution control reaches till the end of the micro 
% control block, packet is processed by the deparser block.
% Orchestration pipeline has only a control block, named 
% orchestration.
% Programmers can implement programmable blocks of Micro pipeline 
% to create custom package types having runtime signature same as 
% unicast 
% or multicast interface.
% Similarly, Orchestration interface is associated with 
% Orchestration pipeline.

\cref{fig:micro-switch-architecture} shows declarations of types 
(\texttt{pkt}, \texttt{sm\_t}, \texttt{es\_t}, \texttt{in\_buf} 
and \texttt{out\_buf}) used in the above mentioned interfaces and 
some other important constructs.


\begin{figure*}
\begin{minipage}[t]{.38\textwidth}
\begin{lstlisting}[frame=none]
extern pkt { /* packet representation */
  byte[] packet; 
  unsigned length;
  void copy_from(pkt pa);
}
/* packet reassembler */
extern emitter {
  void emit<H>(pkt p, in H hdr);
}
\end{lstlisting}
\end{minipage}\vline
\hfill\begin{minipage}[t]{.22\textwidth}
\begin{lstlisting}[frame=none]
/* standard metadata */
struct sm_t { 
  bit<16> pkt_len;
  bit<8> in_port;
}
enum meta_t {
  IN_TIMESTAMP,
  OUT_TIMESTAMP 
}
\end{lstlisting}
\end{minipage}\vline
\hfill\begin{minipage}[t]{.35\textwidth}
\begin{lstlisting}[frame=none]
extern mc_engine {
  mc_engine();
  void set_mc_group(GroupId_t gid);
  apply(es_t, out PktInstId_t);
  
  set_buf(out_buf<O>);
  apply(pkt, out sm_t, es_t, out O);  
}
\end{lstlisting}
\end{minipage}
\begin{minipage}[t]{0.47\textwidth}
\begin{lstlisting}[frame=none]
extern extractor { /* Data Extraction */
  void extract<H>(pkt p, out H hdr);
  void extract<H>(pkt p, out H hdr, in bit<32> size);
  H lookahead<H>();
}
extern es_t {/* Correlated intrinsic metadata */
  void set_out_port(in bit<8>);
  bit<8> get_out_port();
  bit<32> get_value(in meta_t ft);
  void copy_from(es_t es);
}
\end{lstlisting}
\end{minipage}\vline
\hfill\noindent\begin{minipage}[t]{0.52\textwidth}
\begin{lstlisting}[frame=none]
extern in_buf<I> { // used only by architecture
  dequeue(pkt, out sm_t, es_t, out I);
}
extern out_buf<O> {
  enqueue(pkt p, in sm_t sm, es_t es, in O out_args);
  void to_in_buf(in_buf<O>);
  void merge(out_buf<O>);
}
extern mc_buf<H, O> {
  enqueue(pkt, in H, in sm_t, es_t, in O);
}
extern void recirculate<D>(in D data);
\end{lstlisting}
\end{minipage}
\caption{Declarations in Micro-Switch Architecture}
\label{fig:micro-switch-architecture}
\end{figure*}



\subsection{Logical Externs}
\label{sec:logical-externs}

\paragraph{Packet Extern.}
To model a packet as a part of an element of the buffers in 
\uswitch's programming model (\cref{fig:uswitch}), \uarch declares an 
extern object, \texttt{pkt} (\cref{fig:micro-switch-architecture}.
The \texttt{pkt} instance, in parameters of every processing-block, 
is 
supplied by \uswitch.
Also, \uswitch allows to create compile-time copies of packets 
by declaring \texttt{pkt} instances and initializing them using the 
\texttt{copy\_from} method. \hse{..in implementation of the control 
block of only the orchestration pipeline}

% The \texttt{copy\_from} method initializes its caller instance with 
% content of \texttt{pa} without modifying the argument.
% \uswitch considers this method as a compile-time known packet 
% replication, whereas multicast as a runtime packet-replication.
To extract and insert data in \texttt{pkt}, \uarch provides two 
externs objects, \texttt{extractor} and \texttt{emitter}.
The \texttt{extractor} and \texttt{emitter} externs can not be 
instantiated, their instances are provided by the \uswitch as 
parameters in parser and deparser declarations of \texttt{Unicast} 
and \texttt{Multicast} interfaces. 

\paragraph{Correlated Intrinsic Metadata.}
Due to requirement from network monitoring and debugging applications,
architectures of real targets usually provide intrinsic per-packet 
metadata that are correlated. e.g., to measure every packet's queuing 
latency through the device, the timestamps required to compute 
queuing latency can be measured only after the packet's out port is 
finalized and packet is enqueued in appropriate queue.

To capture such dependency among intrinsic metadata, \uarch provides 
a stateful extern, \texttt{es\_t}. The extern exposes methods to 
access correlated intrinsic metadata. In addition, \uarch declares an 
enumerator, called \texttt{meta\_t}. Each value in the enumerator 
associated with a immutable intrinsic metadata populated only by the 
target for every packet (e.g., \texttt{IN\_TIMESTAMP}, 
\texttt{OUT\_TIMESTAMP} etc). The \texttt{es\_t} extern declares a 
method (\texttt{get\_value}), parameterized on the enum, that allows 
to read value, populated by the target, for every such field.

% For example \texttt{set\_out\_port} and \texttt{get\_out\_port} 
% allow, respectively, sets and gets output port for the packet.
% \uarch defines intrinsic metadata for the logical target \uswitch.
% For every real-target architecture , \ucomp maintains mapping of 
% its 
% logical intrinsic metadata with the metadata of the architecture.
% This mapping is used for transforming \uprograms to a given 
% architecture-specific code.
% 
% 
% 
%  The first parameter with \texttt{in} direction is of 
% \texttt{meta\_t} type indicating a particular metadata field. The 
% second parameter with \texttt{out} direction provides value of the 
% field.
% \ucomp allows repeated usage of the extern's functions in the 
% single 
% control block of \uarch pipelines.
% If \emph{get\_value} occurs before \emph{set\_egress\_port} on any 
% possible execution control path, \ucomp raises a compile-time 
% error.



\begin{figure*}[!ht]
\noindent \begin{minipage}[t]{.50\textwidth}
\begin{lstlisting}[frame=none, escapechar=!]
/* router.p4 */
// package type declaration of !{\color{commentcolor}{\uprograms for protocols}}! 
!\colorbox{mygray}{ipv6}!(pkt p, inout sm_t sm, es_t es, 
    out bit<16> nh_id);
!\colorbox{mygray}{ipv4}!(pkt p, inout sm_t sm, es_t es, 
    out bit<16> nh_id);
// implement unicast interface for router package
parser P(extractor ex, pkt p, out empty_ht h, inout data_t d) {
  state start { transition accept; }
}
control C(pkt p, inout empty_ht h, inout sm_t sm, es_t e, 
!\colorbox{mygray}{out bit<16> nh\_id, inout bit<16> type}!) {
  apply {
    switch (!\colorbox{mygray}{type}!) {
      0x0800:!\colorbox{mygray}{ipv4\_i.apply(p, sm, e, nh\_id);}!
      0x86DD:!\colorbox{mygray}{ipv6\_i.apply(p, sm, e, nh\_id);}!
    }
  }
}
control D(emitter em, pkt p, in empty_ht h) {
  apply { }
}
!{\subcaption[]{router \uprogram}\label{subfig:router}}!
/* main.p4 */
!\colorbox{mygray}{router}!(pkt p, inout sm_t sm, es_t es, 
!\colorbox{mygray}{out bit<16> nh\_id, inout bit<16> type}!);
\end{lstlisting}
\end{minipage}\hspace{-4pt}\vline
\hfill\begin{minipage}[t]{.50\textwidth}
\begin{lstlisting}[frame=none, escapechar=!]
parser P(extractor ex, pkt p, out hdr_t h) {
  state start {
    ex.extract(p, h.eth); transition accept;
  }
}
control C(pkt p, inout hdr_t h, inout sm_t sm, es_t es) {
  !\colorbox{mygray}{bit<16> nh\_id; router() route; }!
  action drop () {}           
  action forward(bit<48> dmac, bit<48> smac, bit<8> port) {
    h.eth.dstMac = dmac; h.eth.srcMac = smac;
    es.set_out_port(port);
  }
  table forward_tbl {
    key = { nh_id : exact; } 
    actions = { forward; drop; }
  }
  apply {
    !\colorbox{mygray}{route.apply(p, sm, es, nh\_id, 
h.eth.etherType);}!
    forward_tbl.apply(); 
  }
}
control D(emitter em, pkt p, in hdr_t h) {
  apply { em.emit(p, h.eth); }
}
ModularRouter(P, C, D) main;
\end{lstlisting}
% 0x8847:!\colorbox{mygray}{mpls\_i.apply(p, sm, es);}!
\subcaption[]{ModularRouter \uprogram with main 
instance}\label{subfig:router-main}
\end{minipage}
\caption[]{Modular Router using \uarch \footnotemark}
\label{fig:modular-router}
\end{figure*}
\footnotetext{For brevity, we have skipped the unused parameters in 
parser, control blocks and \upackage type declarations of 
\uprograms.}


% We illustrate modular programming and composition using the logical 
% constructs introduced till now.

\paragraph{Example: Modular Router Using \texttt{Unicast} interface.}
\cref{subfig:router} shows code snippet of a \upackage, 
\texttt{router}, implementing the \texttt{Unicast} interface type 
along with the declarations of \upackages \texttt{ipv6} and 
\texttt{ipv4}.\footnotemark[\value{footnote}] In 
\texttt{router.p4}, \texttt{ipv4} and \texttt{ipv6}, each declare 
a user-defined parameter, \texttt{nh\_id}, as a part of run-time 
parameters with packet and intrinsic metadata. The 
\texttt{router} (in \texttt{main.p4}) declares an additional 
parameter, \texttt{type}. Such user-define parameters allow to pass 
data across \upackages, providing great flexibility for composition.

The \texttt{ModularRouter} \uprogram in 
\cref{subfig:router-main}, parses the ethernet header and invokes 
(highlighted code) the instance \texttt{route} by calling 
\texttt{apply} method. The method call is supplied with the partial 
packet `\texttt{p}', without ehternet header. The \texttt{router} 
package uses its \texttt{type} parameter to invoke an instance of 
appropriate routing protocol package. As a result, it populates 
\texttt{nh\_id} parameter passed as an \texttt{out} argument.


\paragraph{Input/Output Buffers.}
Representative to logical buffers in programming model for \uswitch, 
\uarch declares \texttt{in\_buf} and \texttt{out\_buf} externs. 
Programmers can use them to invoke other programs in implementation 
of 
the control block of the \texttt{Orchestration} interface. As 
\uswitch does not allow to fetch multiple packets at time from input 
buffer, the \texttt{in\_buf} extern has \texttt{dequeue} method that 
can be used only by the \uswitch. However, programmers can 
instantiate 
the extern and use them to pass as arguments to other 
\upackages. The \texttt{out\_buf} extern has, \texttt{enqueue} 
and \texttt{merge}, methods to store packets processed by callee 
\upackages. In addition, it provides \texttt{to\_in\_buf} to move the 
elements of the caller to the instance of \texttt{in\_buf} type
passed as the argument. Note, the \texttt{mc\_buf} extern allows to 
store parsed headers, unlike \texttt{in\_buf} and \texttt{out\_buf} 
externs. It is designed to be used along with \texttt{mc\_engine} to 
express multicast packet-processing, where as \texttt{in\_buf} and 
\texttt{out\_buf} are designed for generic composition interface.


\paragraph{Multicast Extern.}
To avoid compromising expressiveness of \uprograms, \uswitch models 
packet replication at run-time using an extern, \texttt{mc\_engine}, 
declared in \uarch. The \texttt{mc\_engine} can be instantiated 
inside 
the control blocks while implementing the \texttt{Multicast} 
interface 
(shown below).
\begin{lstlisting}[frame=none, escapechar=!]
control mc(pkt p, hdr_t h, sm_t s, es_t e, 
!\colorbox{mygray}{mc\_buf<hdr\_t, out\_t> hb}!) {
  !\colorbox{mygray}{mc\_engine mce;}!  PktInstId_t id; 
  !\colorbox{mygray}{out\_t oa;}! // some out args
  action replicate(GroupId_t gid) {
    !\colorbox{mygray}{mce.set\_mc\_group(gid);}!
  }
  table MulticastRouting{ key = { ... } 
    actions = { replicate; }
  }
  table mac{ ...}
  apply {
    MulticastRouting.apply();
    !\colorbox{mygray}{mce.apply(es, id);}!//similar to C's fork
    mac.apply();
    !\colorbox{mygray}{hb.enqueue(h, sm, es, oa);}!
  }
}
\end{lstlisting}
The control block of \texttt{Multicast} provides 
\texttt{mc\_buf} as one of the parameters to store copies of parsed 
headers, unparsed packet, intrinsic metadata and argument data 
related 
to the packet. 
% Programmers can use \texttt{set\_mc\_group} method in 
% actions or apply blocks to set a replication group for the packet.
To create copies of the packet, programmers can invoke the 
two-arguments \texttt{apply} method. Logically, at run-time the call 
spawns number of \upipelines, each processing one replica, according 
to CP configurations. In every \upipeline, all the reachable 
statements from the call are executed by the replica. The two 
parameters passes required information (\texttt{es\_t} and 
\texttt{PktInstId\_t}) for each replica.
% first argument provides an instance of 
% \texttt{es\_t} having out port already set for the replica of the 
% packet.
% The second argument having \texttt{out} direction provides packet 
% instance id to identify the replica.
Due to space constraint, we skip the detail description of two more 
methods, \texttt{set\_buf} and four-arguments \texttt{apply}, which 
facilitate nested invocation of \upackages with multicast interface. 

% For example, had \texttt{ipv4} and 
% \texttt{ipv6} implemented using multicast interface, the 
% \texttt{forward} table in the \texttt{Router} \uprogram have to be 
% applied on all the copies of partial packet.
% The caller (\texttt{Router}) can cascade multicast processing on 
% partial packets. It can $(1)$ store the partial copies, generated 
% by 
% the callee, into an instance of \texttt{mc\_engine} using 
% \texttt{set\_buf} and $(2)$ invoke the apply method to process each 
% copy using subsequent statments). 




% \begin{figure}[htb]
% \begin{lstlisting}[frame=none, escapechar=!]
% control mc(pkt p, hdr_t h, sm_t s, es_t e, 
% !\colorbox{mygray}{mc\_buf<hdr\_t, out\_t> hb}!) {
%   !\colorbox{mygray}{mc\_engine mce;}!  PktInstId_t id; 
%   !\colorbox{mygray}{out\_t oa;}! // some out args
%   action replicate(GroupId_t gid) {
%     !\colorbox{mygray}{mce.set\_mc\_group(gid);}!
%   }
%   table MulticastRouting{ key = { ... } 
%     actions = { replicate; }
%   }
%   table mac{ ...}
%   apply {
%     MulticastRouting.apply();
%     !\colorbox{mygray}{mce.apply(es, id);}!//similar to C's fork
%     mac.apply();
%     !\colorbox{mygray}{hb.enqueue(h, sm, es, oa);}!
%   }
% }
% \end{lstlisting}
% \caption{Multicast Example}
% \label{fig:multicast-example}
% \end{figure}



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%% MICRO P4 Compiler %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{MicroP4 Compiler (\ucomp)}
\label{sec:compiler}

The constructs of \uarch and programming model of the 
logical target \uswitch, together, allow writing modular \uprograms  
that are specific to the logical target. So, to transform these 
programs into a single dataplane prorgam for a given target, 
we design \ucomp. It composes all the \uprogram dependent on by the 
\texttt{main} porgram and translates the composed program 
for a specified target architecture. We explain its design and key 
transformations that enables composition and complements \uarch and 
\uswitch to realizes portable and modular programming.

\hse{CONT}

\begin{figure}[tbh]
  \centering
  \includegraphics[width=\linewidth]{workflow}
  \caption{Workflow for building dataplanes in \ulang}
  \label{fig:workflow}
\end{figure}
\ucomp transforms parsers and deparsers of the main and callee package types into match-action control blocks.
It synthesizes new parser and deparser for the main package.
The synthesized parser accepts every packet with length greater than the minimum length, called \emph{min-packet-size}, derived by static-analysis of the program.
For every accepted packet, the synthesized parser at most extracts a fixed number, called \emph{extract-length}, of bytes to a stack, called \emph{byte-stack}, of one-byte headers.
Programs may increase or decrease size of packets, therefore, the estimated size of byte-stack can be greater than extract-length.
The synthesized deparser emits all valid one-byte headers from the byte-stack.


We perform compile-time analysis of parser, control and deparser blocks to estimate min-packet-size, extract-length and the size of byte-stack to process packets, as explained in section \ref{subsection:extract-length-and-byte-stack-size}. 
\ucomp executes transformed parsers and deparsers in the match-action stages using the byte-stack.
For each program, \ucomp creates metadata variables, called \texttt{field-variables} for the header fields used in the program's control block.
The header fields are substituted with the metadata variables in control blocks of the program.
\ucomp discards types and instances of the headers of each package.
\ucomp synthesizes a single bit \emph{valid} metadata variable for each header instance to record its presence in the packet.
\texttt{setValid} and \texttt{setInvalid} method-call statements of every header instance is replaced with assignments on the related \emph{valid} metadata variable.
Execution of parsers in match-action stages copy values from the appropriate locations in the byte-stack to the variables.
It also updates valid metadata variables which are later used by the deparser to copy back field-variables to byte-stack.


\hs{TODO: say Simple parser is a parser without stacks and variable-length header. 
Section \ref{subsection:parser-to-match-action-table} discuss about converting simple parser into a match-action table. Section \ref{subsection:header-stacks-variable-length-headers} converts parsers with header stacks or variable-length header into simple parser}


\subsection{Extract Length and Byte-Stack Size}
\label{subsection:extract-length-and-byte-stack-size}
As \ulang allows nested calls of package instances, evaluation of extract-length and byte-stack size is a recursive process.
\ucomp performs symbolic execution to evaluates extract-length and byte-stack size of every callee package in every control path in the CFG of the caller's control block.


The symbolic execution of a parser block enumerates every possible path from the start to the accept state in the parse graph.
For every path, it computes total number of bytes extracted by \texttt{extract} method call statements.
The \texttt{extract} method call statements on a path are evaluated by increasing the number of extracted bytes by size of the header instance specified in the argument.
We define the length of a path $x$ in the parse graph a package $a$'s parser, $lp_{a}(x)$, as total number of bytes extracted from the start to the accept state.
And, the extract-length of a package $a$'s parser is defined as the longest path in its parse graph, as shown in (\ref{extract-length-parser}).
Programs' extract-lengths also depend on their callees in their control blocks.
For a package $a$'s control block, we define the extract-length, $lc_{a}(x)$, of a control path $x$ as the maximum number of bytes required to process all the callees in the path.
The extract-length of the package $a$'s control block is defined as longest path in the CFG (\ref{extract-length-control}).
\begin{align}
E_{p}(a)\; =& \; \max_{x}\left\{lp_{a}(x)\right\} \label{extract-length-parser} \\
E_{c}(a)\; =& \; \max_{x}\left\{lc_{a}(x)\right\} \label{extract-length-control} \\
\mathcal{E}l(a)\; =& \; E_{p}(a) + E_{c}(a) \label{extract-length-program}
\end{align}
A package $a$'s extract-length, $\mathcal{E}l(a)$, is sum of extract-lengths of its parser and control block.
It is necessary to discuss increase and decrease in packet size, before we explain our approach to estimate extract-length of a control path ($lc_{a}(x)$) and byte-stack size for a package.



To estimate maximum decrease on a control path, we consider that a packet contains all the header instances which are set to valid or invalid on the path.
The rationale behind considering this scenario is, if a packet already has a header instance, setting it to valid will not impact size. However, setting it to invalid will decrease the packet size.
Similarly for maximum increase, we consider that a packet does not contain any header instance that is set to valid or invalid on the path. 
We evaluate header instances' \texttt{setValid} and \texttt{setInvalid} method call statements on every path in the CFG of the control block.
We denote increase and decrease in packet size on a path $x$ in the CFG of control block of a package $a$ using $i_{a}(x)$ and $d_{a}(x)$, respectively.
Similarly, $\Delta(a)$ and $\delta(a)$ denote maximum increase and decrease in packet size by a package $a$.
$i_{a}(x)$, as defined in (\ref{increase-path}), is the sum of $(1)$ sizes of all the header instances for which the control path has \texttt{setValid} methods call statements and $(2)$ maximum increase in packet size by every callee package $cp$ on the path.
Similarly, $d_{a}(x)$ is computed as show in (\ref{decrease-path}).
% $d_{p}(x)$ is the sum of $(1)$ sizes of all the header instances for which control path \texttt{setInvalid} methods call statements and $(2)$ maximum decrease in packet size by all every callee program $cp$ on the path as shown in \ref{decrease-path}.
\begin{align}
i_{a}(x)\; =& \; \sum_{H.setValid() \in x} sizeof(H) + \sum_{cp.apply()\in x} \Delta(cp) \label{increase-path} \\
d_{a}(x)\; =& \; \sum_{H.setInValid() \in x} sizeof(H) + \sum_{cp.apply()\in x} \delta(cp) \label{decrease-path}
\end{align}
The header instances which are not emitted by the deparser but extracted by the parser of a package decrease their packet's size. 
$d_{p}(x)$ is incremented by the size of such header instances for every path $x$.
We define maximum increase $\Delta(a)$ and decrease $\delta(a)$ in packet size by a package $a$ as shown in (\ref{increase}) and (\ref{decrease}), respectively.
\begin{align}
\Delta(a)\; =& \; \max_{x} \left\{ i_{a}(x) \right\} \label{increase} \\
\delta(a)\; =& \; \max_{x} \left\{ d_{a}(x) \right\} \label{decrease}
\end{align}

% Callee packages may parse and deparse packets, thereby, increase or decrease size of packets.
% Caller packages must extract sufficient number of bytes to process callees' parsers. Also, Callers must have byte-stack size large enough to process their own deparsers along with callees'.

Now, we define the extract-length ($lc_{a}(x)$) of a control path $x$ in the CFG of package a $a$'s control block as a function of the callees' extract-length ($\mathcal{E}l(cp)$) and maximum decrease in packet size ($\delta(cp)$).
Let's assume that a control path $x$ invokes N number of callee packages in increasing order of their numbers. 
The $i$the callee may decrease the size of packet resulting in available bytes lesser than parser extract-length of (i+1)th callee package ($E_{p}(i+1)$).
Figure \ref{fig:sequential-callees} shows the execution scenario of two callee packages invoked in the same control path in the CFG of a caller's control block.
The ipv6 and ipv4 states in the parsers of callee1 and callee2 transit to the accept state.
There are two control paths in the control block of callee1. One invalidates mpls header instance and another sets a new header (ipv4) to valid.
A control path of the first callee removes the mpls header from the packet, thereby, decreasing the packet size by four bytes.
The subsequent callee extracts eth, IPv6 and IPv4 headers from the packet.
\ucomp parser should extract 78 bytes to process $(1)$ removal of mpls header by the first callee and $(2)$ the logest path (eth-IPv6-IPv4) in the parse-graph of the subsequent callee package.
\begin{figure}[!h]
    \centering
    \includegraphics[trim=0 396 487 0, clip,scale=0.5]{sequential-callees}
    \caption{Multiple Callees in a control path}
    \label{fig:sequential-callees}
\end{figure}
Therefore, we take into account extract-length of every callee package's parser along with maximum decrease in packet size by the callee's predecessors in the control path $x$ to compute $lc_{a}(x)$, as shown in (\ref{extract-length-control-path}).
\begin{align}
lc_{a}(x) \; =& \; \max_{p} \left\{ \left( \sum_{i=0}^{i<p} \delta(i) \right)+ \mathcal{E}l(p) \right\},&p \in [0,N] \label{extract-length-control-path} \\
\mathcal{B}s_{a} \; =& \; \mathcal{E}l(a) + \Delta(a) & \label{byte-stack-size-package}
\end{align}
Finally, we define byte-stack size of a package $a$, $\mathcal{B}s_{a}$ (\ref{byte-stack-size-package}), as the sum of its extract-length and maximum increase in packet size.
For the example shown in Figure \ref{fig:sequential-callees}, the byte-stack size of the caller is 98, 20 bytes (due to ipv4.setValid()) in addition of its extract-length.


\subsection{Parser To Match-Action Table}
\label{subsection:parser-to-match-action-table}
\begin{figure*}[!ht]
    \begin{subfigure}[b]{0.25\linewidth}
        \centering
        \includegraphics[trim=4 270 596 0, clip,scale=0.37]{parser-transformation-example}    
        \caption{An example P4 Parser}
        \label{subfig:parser}
    \end{subfigure}
    \begin{subfigure}[b]{0.26\linewidth}
        \centering
        \includegraphics[trim=0 285 794 0, clip,scale=0.37]{parser-example-se-1}
        \includegraphics[trim=0 285 794 0, clip,scale=0.37]{parser-example-se-2}
        \caption{Parser Symbolic Execution}
        \label{subfig:parser-symbolic-execution}
    \end{subfigure}
    \begin{subfigure}[b]{.47\linewidth}
    \centering
    \begin{lstlisting}[frame=none]
key = { b[12]++b[13]:exact; // rest Ternary
  b[20]; b[23]; meta.data1; meta.data2;
  b[53].isValid(); b[73].isValid();}
actions = { cp_eth_ipv4_tcp;
  cp_eth_ipv6_tcp; set_parser_error;}
const entries = {
  (x0800,_,x6,_,xFF,1,_):cp_eth_ipv4_tcp();
  (x86DD,x6,_,xFF,_,_,1):cp_eth_ipv6_tcp();
}
default_action : set_parser_error();
\end{lstlisting}
\vspace*{-10pt}
\caption{Match-Action Control Block}
\label{subfig:parser-mat}
\end{subfigure}
\caption{Parser to Control Block Transformation}
\label{fig:parser-to-control-block-transformation}
\end{figure*}

% P4 parser blocks describe parse graphs as state machines.
% Real target devices contain programmable parser module that can be programmed using parse graphs.
% From the design of programmable parser \cite{6665172}, we make following observations.
Programmable parsers \cite{6665172} are implemented as finite state machines using buffer, Ternary Content-Addressable Memories (TCAM) and Action RAM. 
TCAM matches values of current state, fields or variables to identify next state.
Based on the match, headers are copied from byte stream followed by current state update.
Programmable parsers essentially perform repeated match-action operations.
% Network packets are of finite length, hence they can be parsed in a finite number of ways.
Successful parsing of a packet is essentially finding a match for a finite number of bytes from a finite set of values.
Every path enumerated by symbolic execution identifies possible byte locations to match for extracting a set of headers instances.
We leverage match capability of TCAM in match-action stages to match simultaneously all possible byte locations pertaining to every path from start to the accept state.
The action associated with the matched entry copies values from the appropriate locations in the byte-stack to local metadata synthesized for used header fields. 

We describe transformation of parser to match-action control block using the example shown in figure \ref{subfig:parser}.
The parser has four states to extract standard Ethernet, IPv4, IPv6 and TCP headers of size 14, 20, 40 and 20 bytes, respectively.
In general, we consider that parser state may use any metadata or variable to transit to next state. 
As an example, \emph{tcp} state transits to the accept state based on value (0xFF) of \texttt{var\_y} variable which is updated by either \emph{ipv4} or \emph{ipv6} states.
The symbolic execution of the parser computes two possibles paths from the start state to the accept state.
It also computes byte locations for header (e.g., eth.ethType, ipv6.nexthdr, ipv4.protocol) fields used in select expressions of states in the path.
If the select expression depends on local variables, it performs Forward Substitution \cite{Padua:1986:ACO:7902.7904} on every path to eliminate data dependency.
Figure \ref{subfig:parser-symbolic-execution} shows evaluated parser states and two paths generated by symbolic execution with forward substitution.
Every extract method-call statement is transformed into assignments from the byte-stack to field-variables associated with the header instance passed as an argument to the method-call.
In addition, valid metadata variable pertaining to the header instance is set.
We synthesize match-key using union of the select expressions in all the states on every path.
The match-key also comprises valid bit flag of the last byte extracted on every path to consider packet-length in the byte-stack.
For each path, we synthesize an action (e.g., \texttt{cp\_eth\_ipv4\_tcp} in Figure \ref{subfig:parser-mat}) comprising assignment statements in all the states on the path.
We create a match-action entry for every path using case values in select expressions and the action synthesized for the path.
For example, in the first entry shown in Figure \ref{subfig:parser-mat}, x0800, x6, xFF are match-values for the first, third and fifth keys to parse byte-stack as ehternet, ipv4 and tcp headers.
The second and the forth keys can have any values, hence they are matched with don't care values.




% The select expression in transition statement could be a header field, metadata or local variable declared in the parser.
% The value of select expression of a state may depend on its ancestors' parser statements. <<as shown in diagram>>
% Therefore, we perform Forward Substitution on select expressions in evaluated instances of states
% % (https://dl.acm.org/citation.cfm?id=7904)
% on each path and eliminate such data dependency.

% We synthesise local binary variables, called \emph{visit},  for each parser state to track the state transition of the parser's FSM.
% For every evaluated instance of a parser state, we synthesise an action comprising its parser\-Statements and replace extract method call statements to assignment statements.
% The assignment statements copies bytes from the buffer array to header instances' fields according to their sizes.
% Next, we add pop method call with the header size as the argument to remove the header from the byte array.
% We insert setValid method call statement for the extracted header instances.
% We add an assignment statement to set visit variable associated with the parser state.




\subsection{Deparser To Match-Action Table:}
\label{subsection:deparser-to-match-action-table}
The deparser blocks of \uarch's pipelines are the control blocks with emitter as one of the parameters.
\ucomp replaces the \texttt{emitter} instance's \texttt{emit} method-call statements with match-action table to transform deparser into normal match-action control blocks.
The match-action table copies back field-variables to appropriate locations in byte-stack based on values of valid metadata variables associated with header instances. 
The control block of the pipeline may set or reset validity of header instances and, thereby, modifying the size of the packet.
In case of increase in packet size, byte-stack is always large enough to hold new headers.
If a deparser decreases the packet size, subsequent parsers may set \texttt{packet\_too\_short} error only if packet-length on the wire is less than the extract-length and greater than the min-packet-size for the main package.

The symbolic execution of a deparser derives the emit order of header instances in the block.
Using the size of header instances and the emit order, we compute offsets in byte-stack to copy back field-variables and to insert new header fields.
The match key comprises valid metadata variables associated with each header instance in the package.
For every possible combination of valid headers, we synthesize a series of operations on byte-stack as an action to copy field-variables and to move data in byte-stack.
The control block of callee1 shown in Figure \ref{fig:sequential-callees} invalidates the mpls header from packets if the execution follows a particular control path.
Recall that, the parser synthesized by \ucomp extracts 78 bytes in the stack.
If the execution follows control path invalidating mpls header, 60 bytes following the header should be moved up by the offset of 4 in the stack.
The synthesized action performs in-place copy of these 60 bytes. It invalidates the last 4 bytes.
If the control block execution sets ipv4 header instance to valid, bytes after the ipv6 header are pushed down by the offset of 20 to insert ipv4 header instance.


By the end of the midend passes, \ucomp transforms parser and deparser blocks of every package into match-action control blocks, homogenizing abstract-machine of the main package and realizing transition of execution control across callee packages.
However, control blocks of the packages still contain \uarch-specific constructs.
Next, we discuss backend of \ucomp that further transforms the control blocks to create a packet-processing program a given target architecture.


\subsection{Transformation to Target Architecture}
\ucomp's backend transforms all the control blocks by $(1)$ translating \uarch-specific constructs to target-specific ones and $(2)$ allocating the control blocks to the ones in target pipeline model.
\uarch-specific constructs are higher-level abstraction for fixed-function packet-processing blocks and functions in target architecture.
\uarch's externs, \texttt{es\_t} and \texttt{mc\_engine}, provide abstraction for constraint on intrinsic metadata and fixed-function block, packet replication engine.
The \texttt{copy\_from} methods of \uarch's externs (\texttt{pkt}, \texttt{es\_t}) are abstraction for compile-time replication of packet.
Programmers can create multiple copies of packets and intrinsic metadata in implementation of the control blocks of orchestration interface to describe multi-packet processing.
In control blocks of orchestration interface, \ucomp realizes multi-packet processing by identifying a packet-processing sub-graph, called a \emph{thread}, for every initialization (\texttt{copy\_from} method call) statement of a \texttt{pkt} instance.
Then, it prepares \emph{Packet-Processing Schedule} (PPS) of the threads and allocates thread code to packet-processing blocks of the target's pipeline model.
Some target architectures may impose constraint that PPSs must be serializable.
If \ucomp fails to find a serial PPS, it raises a compilation error for such targets. 
% To translate the \uarch-specific constructs, \ucomp partitions and allocates the match-action control blocks to programmable-blocks in pipeline models of the target architecture.





\subsubsection{Allocation to Target Architecture}
\label{subsubsection:allocation-to-target-architecture}
Finally \ucomp translates \uarch's constructs to intrinsic metadata and extern provided by the target architecture.
\ucomp visits PPS nodes in topological order to map threads and cps on target architecture.
It simultaneously partitions all the sub-programs represented by each thread node located at the same topological order in PPS.
It allocates the partitions to packet-processing block according to pipeline model of the target architecture.

For an example, we consider v1model architecture for simple\_switch target.
We create a FSM with two states, named ingress and egress.
It captures restriction on usage of egress\_spec, egress\_port and queuing metadata in ingress and egress blocks.
Each state represents a set of assertions to be verified on nodes while visiting them in topological order.
State transition occurs when the graph traversal can not be continued due to absence of nodes without incoming edges.
In the ingress state, the graph traversal asserts that every visited statement is not $(1)$ a call of apply method of \texttt{mc\_engine}  and $(2)$ \texttt{get\_value} methods of \texttt{es\_t}.
When the traversal can not progress any further state transition happens and we split the thread PDG into two PDGs of visited and non-visited nodes.
In the egress state, the graph traversal asserts every that visited statement is not a method call of \texttt{get\_egress\_port}.
We perform trivial translation of method calls of \uarch's extern with corresponding method calls of target architecture.

There can be multiple edges representing control dependencies between the partitions.
Also, partitions may have live local variables.
We synthesize \emph{partition-metadata}to convert control dependencies into data dependencies and convert live variable to user metadata.
We supply the partition-metadata and live variables as user-metadata parameter between ingress and egress control block to restore execution state.
Finally, {copy\_from} method calls of \texttt{pkt} instances are replaced for v1model with \texttt{clone3} and \texttt{recirculate} or by synthesizing multicast session while setting appropriate thread-id in user-defined metadata.
We can perform similar transformation for other architectures like PSA using appropriate functions provided by them.


% We synthesize \emph{partition} metadata that is assigned a unique value for each control branch in the first partition.
% The second partition uses the metadata and condition on their values to resume execution on appropriate control branch.
% Also, partitioned code may access the same local declaration variables.
% These shared local variables along with the \emph{partition} metadata are passed as user-defined metadata between ingress and egress control block.

% We synthesize per packet user metadata to store thread-id.
% A packet is processed by a thread only if the corresponding thread-id is set in the metadata. 
% We enforce this condition by instrumenting thread code with an if-conditional statement.
% At the end of each thread, next thread-id is set.



\section{Implementation}
\label{sec:implementation}
We have implemented \ucomp by extending the open-source P4 reference
compiler, \texttt{p4c}~\cite{p4c}. For any P4-specific components, our
implementation conforms to the P4-16 specification~\cite{p4lang}. In
addition to the frontend extension needed to support \ulang programs,
\ucomp's midend and backend implementation comprises of
\textasciitilde 6,000 LoCs. As supporting a target architecture
requires an architecture-specific backend, our current prototype
includes a backend for \texttt{v1model}~\cite{v1model.p4}. To support
other targets, \ucomp's can be extended with the corresponding
backend. Finally, we have made our implementation available under an
open-source
license\footnote{\url{https://github.com/anonymized-for-review}}.

In the rest of this section, we focus on the following questions.
\begin{enumerate*}[label=(\roman*)]
  \item How different are \ulang programs (\cref{sec:comparison})?
  \item How can we support new targets (\cref{sec:new-target})?
  \item What are the limitations of \ulang (\cref{sec:limitations})?
\end{enumerate*}


\subsection{Comparison with P4}
\label{sec:comparison}
One of our goals is also to keep the changes to the syntax and grammar
of P4 minimal so that users familiar with P4 can easily adopt \ulang.
We briefly highlight major differences in \ulang compared to P4-16.
First, \ulang allows defining custom package types that enable hiding
the implementation of a packet-processing function and exposing an
interface to reuse the code. This enables modular development of
\ulang programs. Second, \uarch defines interfaces to encapsulate a
set of programmable blocks so that the logical dataplane pipeline can
be extended. Third, \uarch uses explicit information passing between
modules in contrast to implicit global sharing of metadata in P4.
Finally, instead of using target-specific constructs, programmers use
logical \uarch constructs. Apart from these, \ulang conforms to the
semantics of other P4-16 constructs such as externs, control, parser
blocks, etc.

\deleted{Essentially, package types are associated runtime behavior,
unlike P4-16's specification. ... (\texttt{pkt}, \texttt{extractor}
and \texttt{emitter}) compared to ones defined in P4 core library
(\texttt{packet\_in} and \texttt{packet\_out}).}





\subsection{Supporting New Target Architectures}
\label{sec:new-target}
\ucomp's frontend and midend translate \ulang programs into \uarch IR
and perform certain optimizations. They do not perform any
target-specific translations. \ucomp's backend
(\cref{subsubsection:allocation-to-target-architecture}) is
target-specific as it translates the target-independent \uarch IR into
a configuration for the specified target. Specifically, it maps
intrinsic metadata of \uarch to that of the target architecture. For
this, it needs target architecture-specific mappings for fields and
methods corresponding to \texttt{sm\_t}, \texttt{es\_t} and
\texttt{mc\_engine}. These mappings are used for translation. The
backend transforms the IR to conform programmable blocks and externs
declared in the target architecture. Additionally, if the midend of
the target's compiler is available, \ucomp backend can pass the IR to
target compiler's midend to generate executable for the target.
Otherwise, \ucomp synthesizes P4 source code from the IR.

Thus, to support a new target architecture, we need to provide
\ucomp's backend with a mapping from \uarch's logical constructs to
target-specific constructs. Our implementation provides an example of
how to do this for \texttt{v1model}.





\subsection{Limitations}
\label{sec:limitations}
While \ulang enables us to achieve our goals of portable, modular and
composable dataplane programming, our current implementation of \ucomp
has certain limitations. These limitations do not affect modularity
and composability, but slightly limits the portability of
packet-processing code.

\tightparbf{Stateful memories.}
Many applications require stateful processing of packets. To support
these, architectures provide various constructs to maintain state in
the dataplane---e.g., PSA provides counters, meters and registers.
Currently, \uarch doesn't provide a portable abstraction for such
constructs. So, while a \ulang program can still use these constructs
for stateful packet processing, it limits the program's portability
across architectures which differ in these constructs.

\tightparbf{Switch CPU-dataplane interface.}
\uarch does not provide a generic abstraction for communication
between the dataplane and the switch CPU. To use such functionality,
programmers have to use target-specific constructs such as
\texttt{digest} and \texttt{packet\_in} for PSA.

\tightparbf{Device capabilities.}
Target devices support match-action tables with a fixed set of match
capabilities---such as exact, LPM, ternary, and range. \ulang requires
a target to support all match types used in a program and \ucomp does
not transform across different match kinds as it requires translating
table entries at runtime. For example, translating a range match entry
for a target that supports only exact match requires enumerating the
range at runtime.  Our focus is on abstractions and transformations at
compile-time. Similarly, \ulang cannot automatically synthesize
implementations for new checksum computations, action selector, action
profiles.

% There exist unified mechanism and abstraction (Control Plane APIs) to configurable data plane from control plane.
% However, data plane program still lacks an abstract to send data or packets to control plane.
% For example, PSA constructs two different, digest and packet\_in, constructs to send data to control plane.
% There could be more higher-level abstraction that can be translated to either of them.

%% The common practice is to expose varying types of constructs in architecture of the target for stateful packet-processing.
%% For example, PSA provides counters, meters and registers for stateful packet-processing.
%% % Again, such constructs for stateful packet-processing hinders portability.
%% \uarch does not abstract away such stateful constructs and exposes them to programmers.
%% However, it could be feasible to automatically allocate stateful data in program to appropriate type of memory available on device.
%% Compilers of Most programming languages analyze scope and lifetime of variables to allocate them on appropriate type of memory.
%% Currently, \ucomp does not perform any such analysis and relies on specific constructs included in \uarch, limiting portability on targets with different constructs for stateful memory.
%% 
%% The lifetime and scope of such state also varies with applications.





\section{Evaluation}
\label{sec:evaluation}
To test the expressiveness and composability of \ulang, we have
implemented a set of applications in \ulang. We present a subset of
these to illustrate some novel ways in which  we can compose dataplane
programs to build real applications.

\subsection{Composing Packet-Processing Layers}
\label{subsection:composing-packet-processing-layers}
Packets are usually structured into layers of protocols headers, where
each layer is specialized for a specific role and has a specific
layout. Therefore, writing modules for processing a layer or a set of
layers is a natural and desired way to develop dataplane programs as
these modules can be developed incrementally, composed together, and
reused.
\tightparbf{Layered Modularity.}
\uarch's generic interfaces allows programmers to define custom
interfaces for modules to exchange data. These can be used to compose
\ulang modules for packet-processing layers. To demonstrate this, we
built a modular router by composing together independent modules
responsible for processing each layer. For example,
\cref{fig:modular-router} shows how we compose modules for processing
the L2 and L3 headers.
% Figure \ref{fig:incremental-development} shows an example of incremental development, which adds SRH processing to support SRv6 in the network.
% \begin{figure}[!h]
% \begin{subfigure}[b]{\linewidth}
%  \begin{lstlisting}[frame=none]
% // srv6.p4
% header ext_routing_h { ... }; 
% header srh_h { ... }; header ipv6_h { ... }; 
% struct srv_ht { 
%   ipv6_h ipv6; ext_routing_h er; srh_h sr;
% };
% parser P(extractor e, pkt p, out srv_ht h) {
%   state start {
%     e.extract(p, h.ipv6);
%     transition select (h.ipv6.nextHdr) {
%       0x2B : parse_routing_hdr; }
%   }
%   state parse_routing_hdr { ... }
%   state parse_srh { ... }
% }
% control C(pkt p, inout srv_ht h, inout sm_t sm, es_t es) {
%   apply { // copy next segment address from h.sr to h.ipv6.destAddr}
% }
% control D(emitter em, pkt p, in srv_ht h) {
%   apply { 
%     em.emit(p, h.ipv6);
%     em.emit(p, h.er); em.emit(p, h.sr);
%   }
% }
% \end{lstlisting}
% \caption{\texttt{srv6} \uprogram to support IPv6 SRH\cite{srh}}
% \label{subfig:srv6}
% \end{subfigure}
% \begin{subfigure}[b]{\linewidth}
% \begin{lstlisting}[frame=none, escapechar=!]
% 0x86DD : { 
%   !\colorbox{mygray}{srv6\_i.apply(p, sm, es);}!
%   ipv6_i.apply(p, sm, es, nh_id);
% }
% \end{lstlisting}
% \caption{Extending \texttt{router} \uprogram}
% \label{subfig:extending-modular-router}
% \end{subfigure}
% \caption{Incremental Development}
% \label{fig:incremental-development}
% \end{figure}


\tightparbf{Incremental Development.}%
For the same program, suppose we want to replace IP routing with
another approach based on segment routing (SRv6). With \ulang, one can
independently and incrementally develop another module for segment
routing, say \texttt{srv6}, to process IPv6 Segment Routing
Header~\cite{srh}. And, we can reuse this module in our modular router
from \cref{subfig:router-main} as follows:

\begin{lstlisting}[frame=none, escapechar=!]
0x86DD : {
  !\colorbox{mygray}{srv6\_i.apply(p, sm, es);}! // copies next segment address from SRH header's list to IPv6's destAddr field
  ipv6_i.apply(p, sm, es, nh_id);
}
\end{lstlisting}
The snippets shows how we can integrate SRv6 without touching any
other module used in the router.




\subsection{Composing Dataplane Programs of NFs}
\label{subsection:composing-dataplane-programs-of-NFs}

Many network functions (NFs), such as firewall and NAT, process
complete packets across protocol layers. Operators often need to
deploy such programs on devices using different combinations and as
specified by some policy. To enable this, prior work on dataplane
composition, such as P4Bricks~\cite{soni:hal-01632431} and
P4Visor~\cite{Zheng:2018:PLV:3281411.3281436}, and virtualization,
such as HyPer4~\cite{Hancock:2016:HUP:2999572.2999607} and
HyperV~\cite{8038396}, define operators based on certain use cases.
\ulang naturally supports such composition using a combination of
\ulang-specific features such as user-defined package types and native
P4 constructs such as conditionals.

\tightparbf{Composition Operators.}%
The following \ulang snippet from the implementation of orchestration
interface shows an example of how one can express \emph{sequential}
and \emph{override} composition from CoVisor~\cite{188954}.
% \begin{lstlisting}[frame=none, escapechar=!]
% // Sequential: Firewall -> Routing
% firewall.apply(p, sm, es);
% if (sm.drop == false) {
  % // Override: Routing decision
  % elephant_flow_routing.apply(p, sm, es);
  % if (sm.drop == true) 
    % modular_router.apply(p, sm, es);
% }
% p4_int.apply(p, sm, es);
% \end{lstlisting}
\begin{lstlisting}[frame=none, escapechar=!]
// Sequential: Firewall -> Routing -> INT
firewall.apply(p, sm, es);
if (sm.drop == false) {
  modular_router.apply(p, sm, es);
  // Override: routing decision
  elephant_flow_routing.apply(p, sm, es);
}
p4_int.apply(p, sm, es);
\end{lstlisting}

The \texttt{firewall} module may decide to drop a packet by analysing
L2, L3 or more headers. Otherwise, the packet is routed.  Similarly,
\texttt{elephant\_flow\_routing} overrides normal routing. Finally,
\texttt{p4\_int} updates the INT (In-band Network Telemetry)
\cite{Kim2015InbandNT, p4int} header with appropriate information.
Note that even though \uarch does not have a notion of ingress and
egress pipelines, it declares intrinsic metadata which can be mapped
to INT data. For example, \emph{ingress timestamp} of INT is mapped to
\ulang's \texttt{IN\_TIMESTAMP}. When compiling for a target such as
\texttt{v1model}, \ucomp partitions the composed pipeline and
allocates \texttt{p4\_int} to egress control block of v1model
architecture. \todo{discuss and clarify example}

Another interesting example of composition is the \texttt{A-B Testing}
operator defined in P4Visor\cite{Zheng:2018:PLV:3281411.3281436}.
\ulang can implement it as follows:
\begin{lstlisting}[frame=none, escapechar=!]
/* A-B Testing in core devices*/
// parser extracts 1 byte header with flag
extractor.extract(p, testHdr);
// Inside control block, the `p` w/o testHdr
if (h.testHdr.testFlag == 1)
  test_prog.apply(p, sm, es);
else
  prod_prog.apply(p, sm, es)
// deparser puts back the test header
emiiter.emit(p, testHdr);
\end{lstlisting}






\subsection{Advanced Processing}
Many applications---e.g., mirroring, statistics collector such as
sFlow and NetFlow, packet history based telemetry as in
NetSight~\cite{179783}, testing mechanisms such as differential
testing~\cite{Zheng:2018:PLV:3281411.3281436}---require selectively
creating copies of packets and processing the copies in a different
manner. \ulang enables such processing through its \texttt{copy\_from}
method in \texttt{pkt} and \texttt{es} externs of \uarch. The
following snippet illustrates creating a copy of parameter \texttt{pk}
and \texttt{e} using the method.
\begin{lstlisting}[frame=none]
struct e_t {}; // empty type
sflow(pkt, inout sm_t, es_t);// Implements Unicast 
control con(pkt pk, inout sm_t s, es_t e, 
    out_buf<e_t> ob) { // `ob' holds out packets
  pkt pk2;  es_t e2;  sm_t s2;
  in_buf<e_t> ib; // in_buffer for another module
  apply {
    pk2.copy_from(pk); // copying
    e2.copy_from(e); s2 = s; // copying
    sflow.apply(pk2, s2, e2); // sflow on copy
    ob.enqueue(pk, s, e); // puting original in ob
    ob.enqueue(pk2, s2, e2); // copy in ob
    ob.to_in_buf(ib); // moves all elements to ib
    modular_router_orch.apply(ib, ob);
  }
}
\end{lstlisting}
The \texttt{sflow} module processes the copy of the packet and
metadata.  Then, the original packet as well as the processed copy are
queued into the output buffer \texttt{ob}. \texttt{to\_in\_buf} moves
the contents of \texttt{ob} to another buffer, \texttt{ib}, and resets
\texttt{ob}. Finally, the \texttt{modular\_router\_orch} routes
packets between modules.





\subsection{Discussion On Evaluation}
In this paper, the focus of our framework is on developing abstractions, interfaces and their compiler transformations to enable target-agnostic reuse of programs. However, the transformations by \ucomp to lower-level architectures may cause resource overhead in targets. 
We highlight some of the key insights of \ucomp to understand possible source of overheads and opportunities for optimizations.

\subsubsection{Hardware Resource Consumption}. 
\ucomp performs static analysis of \uprograms to find the required size of byte-stack (\cref{subsection:extract-length-and-byte-stack-size}) and synthesize a parser/deparser to extract and emit required packet bytes in byte-stack (\cref{subsection:parser-to-match-action-table}). 
It transforms parser/deparser blocks of P4 executed in packet-parser in hardware to a match-action table executed in hardware stages. 
The data plane programs use two crucial resource available on RMT based hardware devices.


\textbf{$(1)$ Packet Header Vector(PHV)} stores parsed headers and data (user-define metadata and local declarations).
The size of byte-stack directly affects consumption of PHV in the same way as size of all parsed headers of monolithic P4 programs. 
Because, both remains in scope and live throughout all the stages in hardware pipeline. We term such utilization of PHV as \textbf{global usage}.

To compare global usage, let's assume that the caller shown in Figure \ref{fig:sequential-callees} is re-written as a monolithic program, called \texttt{mp}.
The \texttt{mp}'s parser is a union of callees' parsers, the total size of headers to execute \texttt{mp} would be 98 (=eth+mpls+ipv6+(2 ipv4)) bytes, which is the same as byte-stack required to execute the caller. 
However, note that extract-length for the caller is 78.
The extra space of 20 bytes in byte-stack is required to accommodate the ipv4 header set by callee1 in its control block.

If we consider absence of setValid and setInValid method calls in callee1's control block, the required size of byte-stack is max(54, 74) = 74.
In this scenario, the caller's byte-stack header would consume less space in PHV compared to mp's headers.

The variables and user-defined metadata used within a control blocks consume PHV, but may not live and consume PHV during entire program execution. 
We term such utilization of PHV as \textbf{local usage}. \ucomp indeed introduces new local variables within control blocks. 
For example, it removes all header instances and creates local variable for header fields accessed in control blocks. 
If for one stage combined, global and local, usages exceeds PHV capacity, allocation of match-action tables to hardware stages would play significant role in fitting composed program on pipeline. 
Our current implementation of \ucomp translates to v1model architecture for \texttt{simple\_switch} target. 
As a part of future work, we will analyze these two aspects, global and local, PHV consumption for real hardware like Tofino \cite{tofino}.


\textbf{$(2)$ The number of Match-Action Hardware Stages:} RMT based devices have limited number of stages in pipeline to execution match-action tables defined in control blocks of P4.
The transformations by \ucomp consumes one hardware stage for every parser or deparser. 
On the other hand, \ucomp greatly simplifies programmability requirement of parser and deparser circuits in hardware. 
Because, \ucomp accepts all packet with size greater than min-packet-size and extract bytes up to extract-length estimated by static-analysis. 
The required programmability can be achieved by using simple counters based design. 
However, as the parser consumes only 1-2\% of chip-area, the gain may not be significant to trade for usage of match-action stages in hardware pipeline. 
Therefore, further optimization would be required to reduce consumption of match-action stages.\\
\textbf{Optimization:} In cases described in \cref{subsection:composing-dataplane-programs-of-NFs}, execution of the match-action table of transformed-deparser is followed by of transformed-parser.
These tables contain static entries. Therefore, creating single table by performing cross-product is feasible, reducing overhead on match-action stages by half.




\subsubsection{Compilation Time}
We are yet to test \ucomp on extensive set of programs and in composition scenario to conclude on compilation time.
However, the selective symbolic-execution results in well-know path explosion problem for programs with high branching factor.
Hence, \ucomp's compile-time analysis can result in significantly huge compilation time.\\
\textbf{Optimization:}
We only evaluate method calls of header types, extractor and emitter during symbolic-executable allowing to spawn lightweight threads for parallel execution.
Further, the computations for extract-length and byte-stack size of \uprograms are highly recursively, therefore they can be avoided by storing and reusing the values during compilation with libraries.



\section{Related Work}

Frenetic Pyretic NetCore, NetKat CoVisor

PSA

P4Visor, Hyper4 HyperV

\section{Conclusion}
We forsee that data plane programs are going to be more and more complex and diverse with novel use cases emerging from in-network computations to packets-carrying-program (SRv6).
Therefore, data plane programming model must facilitate portable and modular programs.
In this work, we identified that data plane programming using P4 needs more than basic (programmable-parser and match-action) primitives for packet-processing.
We showed higher-level abstraction on top of the basic primitives are necessary for writing portable and modular programs.
For composition of program modules, we leveraged the proposed transformation between basic primitives, programmable-parser and match-action.
This transformation promises fundamental change in the way packet-processing can be implemented in hardware.
Though, analysis of resource utilization of our proposed framework yet to be done but there exists encouraging scenarios for optimizations.




\clearpage
%-------------------------------------------------------------------------------
\bibliographystyle{plain}
\bibliography{main}


\appendix
\section{Declarations in \uarch}
\label{appendix:section:micro-switch-architecture}
% \begin{figure*}[h]
% \begin{minipage}[t]{.35\textwidth}
% \begin{lstlisting}[frame=none]
% extern pkt {
%   byte[] packet;
%   unsigned length;
%   void copy_from(pkt p);
% }
% extern emitter {
%   void emit<H>(pkt p, in H hdr);
% }
% \end{lstlisting}
% \end{minipage}\vline
% \hfill\begin{minipage}[t]{.22\textwidth}
% \begin{lstlisting}[frame=none]
% enum meta_t {
%   INGRESS_TIMESTAMP,
%   EGRESS_TIMESTAMP
% }
% struct sm_t {
%   bit<16> pkt_len;
%   bit<8> in_port;
% }
% \end{lstlisting}
% \end{minipage}\vline
% \hfill\begin{minipage}[t]{.41\textwidth}
% \begin{lstlisting}[frame=none]
% extern mc_engine {
%   mc_engine();
%   void set_mc_group(GroupId_t gid);
%   apply(es_t, out PacketInstanceId_t);
%   
%   set_buf(out_buf<O>);
%   apply(pkt, out sm_t, es_t, out O);  
% }
% \end{lstlisting}
% \end{minipage}
% \begin{minipage}[t]{0.40\textwidth}
% \begin{lstlisting}[frame=none]
% extern extractor {
%   void extract<H>(pkt p, out H hdr);
%   void extract<H>(pkt p, out H hdr, in bit<32> size);
%   H lookahead<H>();
% }
% extern es_t {
%   void set_out_port(in bit<8>);
%   bit<8> get_out_port();
%   bit<32> get_value(in meta_t ft);
%   void copy_from(es_t es);
% }
% \end{lstlisting}
% \end{minipage}\vline
% \hfill\noindent\begin{minipage}[t]{0.57\textwidth}
% \begin{lstlisting}[frame=none]
% extern in_buf<I> { // used only by architecture
%   dequeue(pkt, out sm_t, es_t, out I);
% }
% extern out_buf<O> {
%   enqueue(pkt p, in sm_t sm, es_t es, in O out_args);
%   void to_in_buf(in_buf<O>);
%   void merge(out_buf<O>);
% }
% extern mc_buf<H, O> {
%   enqueue(pkt, in H, in sm_t, es_t, in O);
% }
% extern void recirculate();
% \end{lstlisting}
% \end{minipage}
% \end{figure*}


% \begin{figure}[h]
% \begin{lstlisting}[frame=none]
% extern pkt {
%   // byte array representation
%   byte[] packet;
%   unsigned length;
%   void copy_from(pkt p);
% }
% extern emitter {
%   void emit<H>(pkt p, in H hdr);
% }
% extern extractor {
%   void extract<H>(pkt p, out H hdr);
%   void extract<H>(pkt p, out H hdr, in bit<32> size);
%   /// H may be an arbitrary fixed-size type.
%   H lookahead<H>();
% }
% \end{lstlisting}
% \caption{Packet Representation}
% \label{fig:pkt-externs}
% \end{figure}

% \begin{figure}[h]
% \begin{lstlisting}[frame=none]
% enum meta_t {
%   INGRESS_TIMESTAMP,
%   EGRESS_TIMESTAMP
% }
% extern es_t {
%   void set_out_port(in bit<8>);
%   bit<8> get_out_port();
%   bit<32> get_value(in meta_t ft);
%   void copy_from(es_t es);
% }
% \end{lstlisting}
% \caption{\texttt{es\_t} extern}
% \label{fig:msa-egress-spec-extern}
% \end{figure}
% 
% \begin{figure}[h]
% \begin{lstlisting}[frame=none]
% extern in_buf<I> {
%   // used by architecture only
%   dequeue(pkt, out sm_t, es_t, out I);
% }
% extern out_buf<O> {
%   enqueue(pkt p, in sm_t sm, es_t es, in O out_args);
%   void to_in_buf(in_buf<O>);
%   void merge(out_buf<O>);
% }
% extern mc_buf<H, O> {
%   enqueue(pkt, in H, in sm_t, es_t, in O);
% }
% \end{lstlisting}
% \caption{Buffer Representation}
% \label{fig:pkt-buf}
% \end{figure}
% dequeue(pkt, out H, out sm_t, es_t, out O);

% \begin{figure}[h]
% \begin{lstlisting}[frame=none]
% // This can only be used in control block of multicast interface
% extern mc_engine {
%   mc_engine();
%   void set_mc_group(GroupId_t gid);
%   apply(es_t, out PacketInstanceId_t);
%   
%   set_buf(out_buf<O>);
%   apply(pkt, out sm_t, es_t, out O);  
% }
% \end{lstlisting}
% \caption{Multicast Extern}
% \label{fig:msa-multicast-extern}
% \end{figure}



% \begin{figure}[h]
% \begin{lstlisting}[frame=none, escapechar=!]
% struct out_t { /* empty */ }
% control mc(pkt p, hdr_t h, sm_t s, es_t e, !\colorbox{mygray}{mc\_buf<hdr\_t, out\_t> hb}!) {
%   !\colorbox{mygray}{mc\_engine mce;}!  PktInstId_t id; 
%   out_t  oa;
%   action replicate(GroupId_t gid) {
%     !\colorbox{mygray}{mce.set\_mc\_group(gid);}!
%   }
%   table MulticastRouting{
%     key = { h.ipv4.dstAddr : exact; } 
%     actions = { replicate; }
%   }
%   table mac{
%     key = { es.get_port() : exact; } 
%     actions = { mac_update; }
%   }
%   apply {
%     MulticastRouting.apply();
%     !\colorbox{mygray}{mce.apply(es, id);}!//similar to C's fork
%     mac.apply();
%     hb.enqueue(h, sm, es, oa);
%   }
% }
% \end{lstlisting}
% \caption{Multicast Example}
% \label{fig:multicast-example}
% \end{figure}

\begin{figure*}[h]
\begin{lstlisting}[frame=none]
// Unicast
Unicast<H,M,I,O,IO>(pkt p, inout sm_t sm, es_t es, in I in_param, out O out_param, inout IO inout_param) {
  parser u_parser(extractor ex, pkt p, out H hdr, inout M meta, inout sm_t sm, in I in_param, inout IO inout_param);
  control u_control(pkt p, inout H hdr, inout M m, inout sm_t sm, es_t es, in I in_param, out O out_param, inout IO inout_param);
  control u_deparser(emitter em, pkt p, in H hdr);                             
}

// Multicast
Multicast<H,M,I,O>(pkt p, in sm_t sm, es_t es, in I in_param, out_buf<O> ob) {
  parser m_parser(extractor ex, pkt p, out H hdr, inout M meta, in I in_param, inout sm_t sm);
  control m_control(pkt p, inout H hdr, inout M meta, inout sm_t sm, es_t es, inout I in_param, mc_buf<H,O> mob);
  control m_deparser(emitter em, pkt p, in H hdr);
}

Orchestration<I,O>(in_buf<I> ib, out_buf<O> ob) {                         
  control o_control(pkt p, inout sm_t sm, es_t es, in I in_param, out_buf<O> ob);
}    
\end{lstlisting}
\caption{Programmable Blocks for Interfaces}
\label{fig:programmable-blocks-for-interfaces}
\end{figure*}


















\subsection{Transformation To Simple Parser}
% \subsection{Header Stacks \& Variable-Length Headers}
\label{subsection:header-stacks-variable-length-headers}
\ulang allows to use of header stacks with their size known at 
compile-time. 
\ucomp replaces every header stack instance with multiple instances of 
the header type. 
It symbolically evaluates operations on the header stack instances and 
transforms them into appropriate built-in method calls of the 
instances.
P4 provides various sets of computations to use in parser and control 
blocks.
In parser blocks, programmers can use \texttt{next} and \texttt{last} 
operations to iterate through the stack.
These operations along with \texttt{lastIndex} can be used to write 
loops in parsers to extract instances in header stack.
\ucomp unrolls such loops by replicating the parse states in them.
Loop unrolling replaces relative referencing operations, \texttt{next} 
and \texttt{last}, with appropriate header instances in the state 
replicas.
P4 provides \texttt{push\_front} and \texttt{pop\_front} operations on 
stack instances to manipulate elements on top and bottom of the stack.
\ucomp transforms push\_front and pop\_front operations into series of 
assignments and built-in method calls of header instances.
For example, assume that \texttt{hs} is a header stack instance of 
size 3. 
\ucomp synthesize hs0, hs1, hs2 header instances to replace hs.
\texttt{hs\_inst.push\_front(1)} is replaced with \texttt{hs2 = hs1}, 
\texttt{hs1 = hs0} and \texttt{hs0.setInvalid()}.


\ulang allows programmers to define variable-length header types, 
however it imposes a constraint that their variable-length fields must 
contain integer number of bytes at run-time.
% \ucomp splits header type containing fixed and variable-length 
fields into multiple types, where each type contains either 
fixed-length fields or the variable-length field.
\ucomp transforms every parser state with two-argument extract method 
call, used to extract variable-length header, into a sub-parser.
It splits the header type of the instance in the first argument into 
multiple types, where each type contains either fixed-length fields or 
the variable-length field.
Every state in the sub-parser extracts a fixed-number of bytes from 
the packet bit stream.
The sub-parser contains a state having the second argument 
(variableFieldSize) as the expression in its select statement.
The select statement has case-list enumerating all possible values up 
to specified maximum size of the variable-length field.
For each select case, the sub-parser transits to a state extracting a 
fixed number of bytes in the variable-length field.
For example, if variable-length field has maximum size of 40 bytes, 
\ucomp creates 40 states extracting different number of bytes.
The explosion of number of states would only increase number of 
entries in the transformed match-action table of the parser.

% \begin{figure}[H]
% \begin{minipage}[c]{0.45\linewidth}
% \begin{lstlisting}[frame=none]
% header_t[3] hs;
% 
% hs.push_front(1);
% \end{lstlisting}
% \end{minipage}
% \begin{minipage}[c]{0.45\linewidth}
% \begin{lstlisting}[frame=none]
% header_t hs0, hs1, hs2;
% 
% hs2 = hs1;
% hs1 = hs0;
% hs0.setInvalid()
% \end{lstlisting}
% \end{minipage}
% \caption{Extern to }
% \label{fig:}
% \end{figure}




\section{\ucomp}
\subsection{Packet-Processing Schedule}
\label{subsubsection:packet-processing-schedule}
\hs{TODO: this Section \ref{subsubsection:packet-processing-schedule} 
will move out of paper of in appendix. In that scenario, modify  above 
para to hint convincing solution to reader}


\label{subsubsection:packet-processing-schedule}
\begin{figure}[!h]
\begin{lstlisting}[frame=none]
struct e_t {};  struct h_t { ... };
prog(pkt, inout sm_t, es_t, out h_t);
test(pkt, inout sm_t, es_t, out h_t);
log(pkt, inout sm_t, es_t, in h_t, in h_t);
control validate(pkt p, inout sm_t s, es_t e, out_buf<e_t> ob) {
          pkt pt, pm;  es_t et, em;  
/*slice*/ sm_t st, sm; h_t hp, ht;
/*  #  */ apply {
/*  1  */   pm.copy_from(p); // c1
/*  1  */   em.copy_from(e); sm = s;
/*  3  */   pt.copy_from(p); // c3 
/*  3  */   et.copy_from(e); st = s;
/* 2,1 */   prog.apply(p, s, e, hp); 
/* 3,1 */   test.apply(pt, st, et, ht); 
/*  1  */   if (hp != ht) {
/*  1  */     log.apply(pm, sm, em, hp, ht);
/*  1  */     ob.enqueue(pm, sm, em);
/*  1  */   }
/*  3  */   smt.drop = true;
/*  2  */   ob.enqueue(p, sm, e);
/*  3  */   ob.enqueue(pt, smt, et);
          }
       }
\end{lstlisting}
\caption{Multi-Packet Processing}
\label{fig:multi-packet-processing}
\end{figure}
If the main package has callees with orchestration interface, \ucomp 
extracts packet-processing threads and PPS for control block of every 
callee.
\ucomp constructs a Program Dependence Graph(PDG) 
\cite{Ferrante:1987:PDG:24039.24041} having statements as nodes and 
dependencies among them as edges. 
\ucomp  performs a series of transformations on PDG to compute PPS.

% \ucomp treats parameter of orchestration control block or every 
\texttt{copy\_from} method call statement of \texttt{pkt} instance as 
its definition, because they initialize the instance.
% We note that \texttt{pkt} instance argument in \texttt{copy\_from} 
method calls is only used or read.
% Moreover, all other method call statements having \texttt{pkt} 
instances as arguments access (read and modify) the instances, such 
call statements are not considered as their definition statements.
% We define \emph{access-ranges} of a \texttt{pkt} instance's 
definition as span of program statements until the next definition of 
the instance in reached on every possible path in the PDG.
For every initialization statement of a \texttt{pkt} instance, we 
define an \emph{access-range}, analogous to live ranges, as span of 
program statements until the next initialize of the instance in 
reached on every possible path in the PDG.
We merge overlapping access-ranges of multiple initialization of the 
same \texttt{pkt} instance.
If an instance has non-overlapping access-ranges, a new instance for 
every access-range is synthesised to create one-to-one mapping between 
them.
% the instance and its access-range.
Inspired from \emph{program slice} defined in 
\cite{Weiser:1981:PS:800078.802557}, we define \emph{packet slice} 
based on access-ranges.
% of \texttt{pkt} instances' definitions.
A packet slice of a \texttt{pkt} instance is an executable subset of 
PDG, which consists of all the program statements affecting the 
instance's value in its access-ranges.
A set of initialization statements of \emph{pkt} instance with 
overlapping access-ranges is considered as a slicing criteria for a 
given packet instance.
Packet slices can have multiple entry and exist points due to presence 
of conditional statements.
We compute packet slices from the PDG of control block using a method 
similar to one described in \cite{Ferrante:1987:PDG:24039.24041}.
Specifically, we perform a graph traversal in reverse direction of 
edges from every statement at exit points in the access-ranges until 
initialization statements in the criteria are reached.
The graph traversal continues until all possible definitions of every 
variable used in visited statement are reached.
If any variable or extern instance is involved in anti-dependency, it 
is resolved by introducing new variable and renaming.
An example program shown in Figure \ref{fig:multi-packet-processing} 
is sliced with respect to definitions of three instances \texttt{pm}, 
\texttt{p} and \texttt{pt}.


Packet slices of different instances may have common program 
statements due to control and data dependencies.
Therefore, a packet slice may have method call statements processing 
different \emph{pkt} instances than one's initialization statements 
used in slicing criteria.
For the program shown in Figure \ref{fig:multi-packet-processing}, 
slice 1 pertaining to instance \texttt{pm} shares program statements 
with slices 2 and 3 related to \texttt{p} and \texttt{pt}, 
respectively.
We create a packet-processing thread per instance by excluding such 
method call statements from every packet slice but maintain dependency 
among them by creating inter-thread dependency.
% All other common program statements not accessing \texttt{pkt} 
instances are also excluded from threads.
All other common program statements are also excluded from threads of 
\texttt{pkt} instances.
We term such statements \emph{cps} nodes and maintain their control 
and data dependencies with the thread nodes.
% We associate every thread with an identifier, \emph{thread-id}, and 
a set of group-ids, called \emph{clone-group}.
We associate every thread with an identifier, \emph{thread-id}, and 
synthesize metadata for it.
\ucomp synthesizes if-conditional statement in every thread to execute 
its program statements only if its id value is set in thread-id 
metadata.
% Every thread-id identifies a thread based on unique \texttt{pkt} 
instance processed by it.
% In presence of conditional statements, a thread may process a packet 
copied from one of multiple possible packet instances.
% Every group-id identifies set of threads that may process copies of 
the same packet instance.


% and clone-group identifies every possible \texttt{pkt} instances 
from which the thread's packet instance could be initialized.

We follow similar approach to extract threads associated with 
\texttt{in\_buf} instance.
The \texttt{merge} and \texttt{to\_in\_buf} methods of 
\texttt{out\_buf} easily allows to add thread nodes and control 
dependency among them in PPS.

We transform PDG to PPS graph by coalescing all the nodes in a thread 
to a single node while maintaining their control and data dependencies 
with cps and other thread nodes.
We synthesise a variable to transform every control dependency among 
thread nodes to a data dependency.
The thread, which is depended on, sets the variable with a constant 
value and the other thread uses the variable in predicate of new 
if-conditional statement to continue processing on the control path.
If a PPS has a directed cycle involving thread nodes, PPS is not 
serializable.
If the target architecture does not have capability to process 
multiple copy of a packet at the same time, 
\ucomp raises error and lists program statements involved in cycles.
However, a PPS can have cycles involving maximum one thread node and 
cps nodes.
To decide execution thread for cps nodes, we compute strongly 
connected components of PPS graph.
In each component, there can be exactly one thread node and one or 
more cps nodes.
We further transform PPS into a DAG by coalescing cps nodes in a 
component to its thread node.
PPS can still have cps nodes not part of any SCC, such nodes can be 
executed as a part of any thread.
We schedule such cps nodes while mapping the thread components to data 
plane of target architecture.

% Every \texttt{apply} method call statement of \texttt{Multicast} or 
\texttt{Orchestration} type package gets transformed to a thread node 
in PPS.
% \texttt{enqueue}, \texttt{merge} and \texttt{to\_in\_buf} method 
call statements of \texttt{out\_buf} extern's instances capture 
dependence among such threads nodes in PPS.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\end{document}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%  LocalWords:  endnotes includegraphics fread ptr nobj noindent
%%  LocalWords:  pdflatex acks
